import scrapy
import json

class DarkWebSpider(scrapy.Spider):
    name = "darkweb_scraper"

    def start_requests(self):
        # ğŸ”¹ JSON íŒŒì¼ì—ì„œ URL ë¶ˆëŸ¬ì˜¤ê¸°
        with open("onion_links.json", "r", encoding="utf-8") as f:
            onion_links = json.load(f)

        # ğŸ”¹ í¬ë¡¤ë§í•  URL ë¦¬ìŠ¤íŠ¸ ìƒì„±
        for entry in onion_links:
            yield scrapy.Request(url=entry["onion_link"], callback=self.parse)

    def parse(self, response):
        yield {
            "url": response.url,
            "title": response.css("title::text").get(),
            "body_text": response.css("body").get()
        }
